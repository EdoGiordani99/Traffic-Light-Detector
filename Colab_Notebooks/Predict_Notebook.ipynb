{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO20CC0HLdtOVRCJba6YGYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdoGiordani99/Traffic-Light-Detector/blob/main/Colab_Notebooks/Predict_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction Notebook\n",
        "<h2>Vision & Perception Project 2021/2022</h2>\n",
        "<h3>Student: Edoardo Giordani</h3>\n",
        "<h3>E-mail: giordani.2020434@studenti.uniroma1.it</h3>\n",
        "This notebook was used to make inferences on the test set and plot the predicted bounding boxes on them.\n"
      ],
      "metadata": {
        "id": "8n2_o3Z34GWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting Drive"
      ],
      "metadata": {
        "id": "kWKAp-n3dnzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/V&P/TLD"
      ],
      "metadata": {
        "id": "y-aBrmK62WMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Libraries Import"
      ],
      "metadata": {
        "id": "vRUKMJoRcyyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "!pip install albumentations==0.4.6\n",
        "!pip install pytest-shutil"
      ],
      "metadata": {
        "id": "27yoigCtcnb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import albumentations as A\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from matplotlib import pyplot as plt\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from model import create_model\n",
        "from config import (\n",
        "    NUM_CLASSES, DEVICE, CLASSES, MODEL_NAME, PRETRAINED\n",
        ")"
      ],
      "metadata": {
        "id": "lOY-XCd3cuZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE"
      ],
      "metadata": {
        "id": "310tJadXaW6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "5W1k8CPE414y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = 'data/test'\n",
        "\n",
        "WEIGHTS_PATH = 'trainings/1/best_model.pth'\n",
        "\n",
        "THRESHOLD = 0.7"
      ],
      "metadata": {
        "id": "rdXLTyHE4pFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Trained Model"
      ],
      "metadata": {
        "id": "iusdJfEBc1wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(num_classes=NUM_CLASSES, name=MODEL_NAME, pretrained=PRETRAINED)\n",
        "checkpoint = torch.load(WEIGHTS_PATH , map_location=DEVICE)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(DEVICE).eval()\n",
        "\n",
        "print('Model Loaded Correctly')"
      ],
      "metadata": {
        "id": "93z2Zm2WcyDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Prediction"
      ],
      "metadata": {
        "id": "k9r_9ynzYJWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict Function\n",
        "\n",
        "def predict(img):\n",
        "\n",
        "    # Processing to make the image net - compatible\n",
        "    img = img.astype(np.float32)\n",
        "    img /= 255.0\n",
        "    img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "    img = torch.tensor(img, dtype=torch.float).cuda()\n",
        "\n",
        "    #adding the batch dimension\n",
        "    img = torch.unsqueeze(img, 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img.to(DEVICE))\n",
        "\n",
        "    outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "WG5LBi3Gfs21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Functions\n",
        "\n",
        "def take_color(class_name): \n",
        "    if class_name == 'Red Car':\n",
        "        color = (225, 0, 0)\n",
        "\n",
        "    elif class_name == 'Red Ped': \n",
        "        color = (255, 0, 150)\n",
        "    \n",
        "    elif class_name == 'Green Car':\n",
        "        color = (0, 255, 0)\n",
        "\n",
        "    elif class_name == 'Green Ped': \n",
        "        color = (0, 255, 150)\n",
        "\n",
        "    elif class_name == 'Yellow Car':\n",
        "        color = (225, 150, 0)\n",
        "\n",
        "    elif class_name == 'Yellow Ped': \n",
        "        color = (255, 150, 150)\n",
        "    \n",
        "    elif class_name == 'Unk': \n",
        "        color = (255, 0, 255)\n",
        "\n",
        "    return color\n",
        "\n",
        "def visualize_bbox(img, bbox, class_name):\n",
        "\n",
        "    BOX_COLOR = take_color(class_name) # Red\n",
        "    TEXT_COLOR = (255, 255, 255) # White\n",
        "\n",
        "    x_min, x_max, y_min, y_max = bbox\n",
        "   \n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=BOX_COLOR, thickness=12)\n",
        "    \n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 4, 2)    \n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=4, \n",
        "        color=TEXT_COLOR,\n",
        "        thickness = 10\n",
        "    )\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize(image, threshold, outputs):\n",
        "\n",
        "    if len(outputs[0]['boxes']) != 0:\n",
        "        # getting the boxes\n",
        "        boxes = outputs[0]['boxes'].data.numpy()\n",
        "        # getting the scores\n",
        "        scores = outputs[0]['scores'].data.numpy()\n",
        "\n",
        "    # Bounding Boxes Predictions\n",
        "    boxes = boxes[scores >= threshold].astype(np.int32)\n",
        "    bboxes = boxes.copy()\n",
        "\n",
        "    # Class Predictions\n",
        "    pred_classes = [CLASSES[i] for i in outputs[0]['labels'].cpu().numpy()][:len(boxes)]\n",
        "    print(pred_classes)\n",
        "\n",
        "    img = image.copy()\n",
        "    for bbox, class_name in zip(bboxes, pred_classes):\n",
        "        img = visualize_bbox(img, bbox, class_name)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "vP-Kdkk_izhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = glob.glob(f\"{TEST_DIR}/*.jpg\")\n",
        "print(f\"Test instances: {len(test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwcoOZ8WY7KW",
        "outputId": "9e355c9a-bec1-432b-c413-1ee20626ea4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test instances: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img in test_images:\n",
        "    image = cv2.imread(img)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    outputs = predict(image)\n",
        "\n",
        "    visualize(image, THRESHOLD, outputs)"
      ],
      "metadata": {
        "id": "lFRNpuF807Hl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}